{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subjective-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'D:\\Computer Vision Camp\\Computer Vision Homework nr. 5\\utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wicked-centre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: setuptools>=18.0 in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pycocotools) (49.2.1)\n",
      "Requirement already satisfied: cython>=0.27.3 in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pycocotools) (0.29.24)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pycocotools) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (1.20.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "victorian-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: torchvision in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (1.20.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: torch==1.10.0 in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==1.10.0->torchvision) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "martial-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision\n",
    "\n",
    "from PIL.ExifTags import TAGS\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "creative-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,root, data_file, transform):\n",
    "        self.root = root ### mapa cu fotografii\n",
    "        self.transform = transform\n",
    "        self.data = pd.read_csv(data_file, sep=';')\n",
    "        self.imgs = self.data['image_path'].values\n",
    "        self.path_to_data_file = data_file\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        img_path = os.path.join(self.root,self.imgs[idx])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        \n",
    "        for orientation in TAGS.keys() : \n",
    "            if TAGS[orientation]=='Orientation' : break \n",
    "        # Getting the exif\n",
    "        exif=dict(img.getexif().items())\n",
    "        # Rotating the image if the orientation is wrong.\n",
    "        if len(exif)!=0:                                                             \n",
    "            if orientation in exif.keys():\n",
    "                if exif[orientation] == 3 : \n",
    "                    img=img.rotate(180, expand=True)\n",
    "                elif exif[orientation] == 6 : \n",
    "                    img=img.rotate(270, expand=True)\n",
    "                elif exif[orientation] == 8 : \n",
    "                    img=img.rotate(90, expand=True)\n",
    "                    \n",
    "        box_list = self.data[self.data['image_path']==self.imgs[idx]][['x_min','y_min','x_max','y_max']].values\n",
    "        boxes = torch.as_tensor(box_list, dtype=torch.float32)\n",
    "        num_obj = len(box_list)\n",
    "        labels = torch.ones((num_obj,), dtype = torch.int64)\n",
    "        iscrowd = torch.zeros((num_obj,), dtype=torch.int64)\n",
    "        area = (boxes[:,3] - boxes[:, 1]) * (boxes[:,2] - boxes[:, 0])\n",
    "        \n",
    "        image_id = torch.tensor([idx])\n",
    "        \n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "        target['image_id'] = image_id\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "female-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = T.Compose([T.ToTensor()])\n",
    "\n",
    "dataset = DataSet(r'D:\\Computer Vision Camp\\Computer Vision Homework nr. 5\\data',\n",
    "                  r'D:\\Computer Vision Camp\\Computer Vision Homework nr. 5\\handguns.csv',\n",
    "                  transformations)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "train = torch.utils.data.Subset(dataset, indices[:100])\n",
    "test = torch.utils.data.Subset(dataset, indices[100:])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = 1, shuffle=True, collate_fn = utils.collate_fn)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = 1, shuffle=False, collate_fn = utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "variable-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_clase):\n",
    "    \n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.required_grad = False\n",
    "        \n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_clase)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cutting-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "num_clase = 2\n",
    "model = get_model(num_clase).to(DEVICE)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.SGD(params, lr = 0.005, momentum=0.9, weight_decay = 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "governing-hanging",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/100]  eta: 0:08:37  lr: 0.000055  loss: 1.0840 (1.0840)  loss_classifier: 0.9270 (0.9270)  loss_box_reg: 0.1422 (0.1422)  loss_objectness: 0.0102 (0.0102)  loss_rpn_box_reg: 0.0046 (0.0046)  time: 5.1712  data: 0.0110\n",
      "Epoch: [0]  [ 10/100]  eta: 0:07:41  lr: 0.000560  loss: 0.7207 (0.7507)  loss_classifier: 0.5754 (0.5497)  loss_box_reg: 0.1733 (0.1797)  loss_objectness: 0.0053 (0.0130)  loss_rpn_box_reg: 0.0076 (0.0084)  time: 5.1314  data: 0.0124\n",
      "Epoch: [0]  [ 20/100]  eta: 0:06:48  lr: 0.001065  loss: 0.4275 (0.6092)  loss_classifier: 0.2447 (0.4074)  loss_box_reg: 0.1704 (0.1840)  loss_objectness: 0.0053 (0.0112)  loss_rpn_box_reg: 0.0052 (0.0066)  time: 5.1061  data: 0.0109\n",
      "Epoch: [0]  [ 30/100]  eta: 0:05:55  lr: 0.001569  loss: 0.3314 (0.5293)  loss_classifier: 0.1663 (0.3250)  loss_box_reg: 0.1501 (0.1839)  loss_objectness: 0.0077 (0.0135)  loss_rpn_box_reg: 0.0044 (0.0068)  time: 5.0440  data: 0.0094\n",
      "Epoch: [0]  [ 40/100]  eta: 0:05:03  lr: 0.002074  loss: 0.2945 (0.4706)  loss_classifier: 0.1203 (0.2702)  loss_box_reg: 0.1399 (0.1794)  loss_objectness: 0.0099 (0.0138)  loss_rpn_box_reg: 0.0052 (0.0073)  time: 5.0126  data: 0.0078\n",
      "Epoch: [0]  [ 50/100]  eta: 0:04:13  lr: 0.002578  loss: 0.2168 (0.4593)  loss_classifier: 0.0868 (0.2427)  loss_box_reg: 0.1129 (0.1919)  loss_objectness: 0.0221 (0.0171)  loss_rpn_box_reg: 0.0052 (0.0076)  time: 5.0494  data: 0.0079\n",
      "Epoch: [0]  [ 60/100]  eta: 0:03:26  lr: 0.003083  loss: 0.1966 (0.4394)  loss_classifier: 0.0709 (0.2178)  loss_box_reg: 0.1129 (0.1979)  loss_objectness: 0.0146 (0.0161)  loss_rpn_box_reg: 0.0052 (0.0076)  time: 5.3851  data: 0.0073\n",
      "Epoch: [0]  [ 70/100]  eta: 0:02:36  lr: 0.003587  loss: 0.1871 (0.4069)  loss_classifier: 0.0637 (0.1965)  loss_box_reg: 0.1126 (0.1883)  loss_objectness: 0.0059 (0.0148)  loss_rpn_box_reg: 0.0028 (0.0073)  time: 5.5823  data: 0.0070\n",
      "Epoch: [0]  [ 80/100]  eta: 0:01:43  lr: 0.004092  loss: 0.1648 (0.3790)  loss_classifier: 0.0637 (0.1813)  loss_box_reg: 0.0992 (0.1758)  loss_objectness: 0.0024 (0.0146)  loss_rpn_box_reg: 0.0027 (0.0073)  time: 5.2936  data: 0.0076\n",
      "Epoch: [0]  [ 90/100]  eta: 0:00:51  lr: 0.004596  loss: 0.1399 (0.3559)  loss_classifier: 0.0554 (0.1691)  loss_box_reg: 0.0712 (0.1656)  loss_objectness: 0.0063 (0.0140)  loss_rpn_box_reg: 0.0035 (0.0072)  time: 5.0974  data: 0.0055\n",
      "Epoch: [0]  [ 99/100]  eta: 0:00:05  lr: 0.005000  loss: 0.1399 (0.3389)  loss_classifier: 0.0556 (0.1602)  loss_box_reg: 0.0817 (0.1579)  loss_objectness: 0.0063 (0.0137)  loss_rpn_box_reg: 0.0038 (0.0071)  time: 5.1412  data: 0.0071\n",
      "Epoch: [0] Total time: 0:08:38 (5.1898 s / it)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4bf9d7e16c4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Computer Vision Camp\\Computer Vision Homework nr. 5\\utils\\engine.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, data_loader, device)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mmodel_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36msynchronize\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m     \"\"\"\n\u001b[1;32m--> 491\u001b[1;33m     \u001b[0m_lazy_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_synchronize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\simple\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    train_one_epoch(model, optimizer, train_loader, DEVICE, epoch, print_freq = 10)\n",
    "    \n",
    "    evaluate(model, test_loader, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),r'D:\\Computer Vision Camp\\Computer Vision Homework nr. 5\\fix1_ports_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = get_model(num_clase=2)\n",
    "loaded_model.load_state_dict(torch.load(r'D:\\Computer Vision Camp\\Computer Vision Homework nr. 5\\fix1_ports_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code to made a predition.\n",
    "from PIL import ImageDraw\n",
    "# Getting the image.\n",
    "for idx in range(2,20):\n",
    "    img, _ = test[idx]\n",
    "    # Getting the object coordinates.\n",
    "    label_boxes = np.array(test[idx][1]['boxes'])\n",
    "\n",
    "    # Setting the model to eval state.\n",
    "    loaded_model.eval()\n",
    "    # Making the prediction.\n",
    "    with torch.no_grad():\n",
    "        prediction = loaded_model([img])\n",
    "\n",
    "    # Getting an drawing the image.\n",
    "    image = Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Drawing the real box around the object.\n",
    "    for elem in range(len(label_boxes)):\n",
    "        draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]),\n",
    "                       (label_boxes[elem][2], label_boxes[elem][3])],\n",
    "                      outline='green', width=3)\n",
    "    # Drawing the predicted box around the object.\n",
    "    for element in range(len(prediction[0]['boxes'])):\n",
    "        boxes = prediction[0]['boxes'][element].cpu().numpy()                                     \n",
    "        score = np.round(prediction[0]['scores'][element].cpu().numpy(), decimals=4)\n",
    "\n",
    "        if score > 0.2:\n",
    "            draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])],\n",
    "                         outline='red', width=3)\n",
    "            draw.text((boxes[0], boxes[1]), text=str(score))\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-witch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
